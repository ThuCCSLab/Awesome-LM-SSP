# C3. Membership Inference Attacks
- [2025/06] **[SoK: Can Synthetic Images Replace Real Data? A Survey of Utility and Privacy of Synthetic Image Generation](https://arxiv.org/abs/2506.19360)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![USENIX_Security'25](https://img.shields.io/badge/USENIX_Security'25-f1b800)
- [2025/06] **[Leaner Training, Lower Leakage: Revisiting Memorization in LLM Fine-Tuning with LoRA](https://arxiv.org/abs/2506.20856)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[Image Corruption-Inspired Membership Inference Attacks against Large Vision-Language Models](https://arxiv.org/abs/2506.12340)** ![VLM](https://img.shields.io/badge/VLM-c7688b)
- [2025/06] **[What Really is a Member? Discrediting Membership Inference via Poisoning](https://arxiv.org/abs/2506.06003)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[SOFT: Selective Data Obfuscation for Protecting LLM Fine-tuning against Membership Inference Attacks](https://arxiv.org/abs/2506.10424)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![USENIX_Security'25](https://img.shields.io/badge/USENIX_Security'25-f1b800)
- [2025/05] **[Strong Membership Inference Attacks on Massive Datasets and (Moderately) Large Language Models](https://arxiv.org/abs/2505.18773)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[Unveiling Impact of Frequency Components on Membership Inference Attacks for Diffusion Models](https://arxiv.org/abs/2505.20955)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/05] **[Tokens for Learning, Tokens for Unlearning: Mitigating Membership Inference Attacks in Large Language Models via Dual-Purpose Training](https://arxiv.org/abs/2502.19726)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL'25](https://img.shields.io/badge/ACL'25-f1b800)
- [2025/03] **[Membership Inference Attacks on Large-Scale Models: A Survey](https://arxiv.org/abs/2503.19338)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Survey](https://img.shields.io/badge/Survey-87b800)
- [2025/03] **[Privacy Auditing of Large Language Models](https://arxiv.org/abs/2503.06808)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'25](https://img.shields.io/badge/ICLR'25-f1b800)
- [2025/02] **[Towards Label-Only Membership Inference Attack against Pre-trained Large Language Models](https://arxiv.org/abs/2502.18943)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![USENIX_Security'25](https://img.shields.io/badge/USENIX_Security'25-f1b800)
- [2025/02] **[Has My System Prompt Been Used? Large Language Model Prompt Membership Inference](https://arxiv.org/abs/2502.09974)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation](https://arxiv.org/abs/2502.00306)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2025/01] **[Membership Inference Attacks Against Vision-Language Models](https://arxiv.org/abs/2501.18624)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![USENIX_Secuirty'25](https://img.shields.io/badge/USENIX_Secuirty'25-f1b800)
- [2025/01] **[Tag&Tab: Pretraining Data Detection in Large Language Models Using Keyword-Based Membership Inference Attack](https://arxiv.org/abs/2501.08454)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/12] **[LUMIA: Linear probing for Unimodal and MultiModal Membership Inference Attacks leveraging internal LLM states](https://arxiv.org/abs/2411.19876)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[On the Privacy Risk of In-context Learning](https://arxiv.org/abs/2411.10512)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[Membership Inference Attacks against Large Vision-Language Models](https://arxiv.org/abs/2411.02902)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![NeurIPS'24](https://img.shields.io/badge/NeurIPS'24-f1b800)
- [2024/10] **[Scaling Up Membership Inference: When and How Attacks Succeed on Large Language Models](https://aclanthology.org/2025.findings-naacl.234)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![NAACL'25_Findings](https://img.shields.io/badge/NAACL'25_Findings-f1b800)
- [2024/10] **[Mask-based Membership Inference Attacks for Retrieval-Augmented Generation](https://arxiv.org/abs/2410.20142)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2024/10] **[PSY: Posterior Sampling Based Privacy Enhancer in Large Language Models](https://arxiv.org/abs/2410.18824)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Identity-Focused Inference and Extraction Attacks on Diffusion Models](https://arxiv.org/abs/2410.10177)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/10] **[Detecting Training Data of Large Language Models via Expectation Maximization](https://arxiv.org/abs/2410.07582)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Membership Inference Attacks Cannot Prove that a Model Was Trained On Your Data](https://arxiv.org/abs/2409.19798)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Predicting and analyzing memorization within fine-tuned Large Language Models](https://arxiv.org/abs/2409.18858)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Context-Aware Membership Inference Attacks against Pre-trained Large Language Models](https://arxiv.org/abs/2409.13745)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Order of Magnitude Speedups for LLM Membership Inference](https://arxiv.org/abs/2409.14513)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Con-ReCall: Detecting Pre-training Data in LLMs via Contrastive Decoding](https://arxiv.org/abs/2409.03363)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Membership Inference Attacks Against In-Context Learning](https://arxiv.org/abs/2409.01380)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/08] **[PrivacyLens: Evaluating Privacy Norm Awareness of Language Models in Action](https://arxiv.org/abs/2409.00138)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/08] **[MIA-Tuner: Adapting Large Language Models as Pre-training Text Detector](https://arxiv.org/abs/2408.08661)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/08] **[Nob-MIAs: Non-biased Membership Inference Attacks Assessment on Large Language Models with Ex-Post Dataset Construction](https://arxiv.org/abs/2408.05968)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Adaptive Pre-training Data Detection for Large Language Models via Surprising Tokens](https://arxiv.org/abs/2407.21248)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Seeing Is Believing: Black-Box Membership Inference Attacks Against Retrieval Augmented Generation](https://arxiv.org/abs/2406.19234)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2024/06] **[Inherent Challenges of Post-Hoc Membership Inference for Large Language Models](https://arxiv.org/abs/2406.17975)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Blind Baselines Beat Membership Inference Attacks for Foundation Models](https://arxiv.org/abs/2406.16201)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Noisy Neighbors: Efficient membership inference attacks against LLMs](https://arxiv.org/abs/2406.16565)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[LLM Dataset Inference: Did you train on my dataset?](https://arxiv.org/abs/2406.06443)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Is My Data in Your Retrieval Database? Membership Inference Attacks Against Retrieval Augmented Generation](https://arxiv.org/abs/2405.20446)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2024/05] **[Towards Black-Box Membership Inference Attack for Diffusion Models](https://arxiv.org/abs/2405.20771)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[Membership Inference on Text-to-Image Diffusion Models via Conditional Likelihood Discrepancy](https://arxiv.org/abs/2405.14800)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/04] **[Sampling-based Pseudo-Likelihood for Membership Inference Attacks](https://arxiv.org/abs/2404.11262)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Do Membership Inference Attacks Work on Large Language Models?](https://arxiv.org/abs/2402.07841)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/12] **[Black-box Membership Inference Attacks against Fine-tuned Diffusion Models](https://arxiv.org/abs/2312.08207)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![NDSS'25](https://img.shields.io/badge/NDSS'25-f1b800)
- [2023/11] **[Practical Membership Inference Attacks against Fine-tuned Large Language Models via Self-prompt Calibration](https://arxiv.org/abs/2311.06062)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/10] **[User Inference Attacks on Large Language Models](https://arxiv.org/abs/2310.09266)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/09] **[An Efficient Membership Inference Attack for the Diffusion Model by Proximal Initialization](https://openreview.net/forum?id=rpH9FcCEV6)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/08] **[White-box Membership Inference Attacks against Diffusion Models](https://arxiv.org/abs/2308.06405)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2023/03] **[Class Attribute Inference Attacks: Inferring Sensitive Class Information by Diffusion-Based Attribute Manipulations](https://arxiv.org/abs/2303.09289)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Attribute](https://img.shields.io/badge/Attribute-87b800)
- [2022/10] **[Membership Inference Attacks Against Text-to-image Generation Models](https://arxiv.org/abs/2210.00968)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
