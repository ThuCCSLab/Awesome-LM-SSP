# A4. Ethics
- [2025/10] **[SocialHarmBench: Revealing LLM Vulnerabilities to Socially Harmful Requests](https://arxiv.org/abs/2510.04891v1)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/06] **[Democratic or Authoritarian? Probing a New Dimension of Political Biases in Large Language Models](https://arxiv.org/abs/2506.12758)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/05] **[Are Language Models Consequentialist or Deontological Moral Reasoners?](https://arxiv.org/abs/2505.21479)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/12] **[Disentangling Perceptions of Offensiveness: Cultural and Moral Correlates](https://arxiv.org/abs/2312.06861)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/10] **[Unpacking the Ethical Value Alignment in Big Models](https://arxiv.org/abs/2310.17551)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/09] **[DENEVIL: TOWARDS DECIPHERING AND NAVIGATING THE ETHICAL VALUES OF LARGE LANGUAGE MODELS VIA INSTRUCTION LEARNING](https://openreview.net/forum?id=m3RRWWFaVe)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/05] **[From Text to MITRE Techniques: Exploring the Malicious Use of Large Language Models for Generating Cyber Attack Payloads](https://arxiv.org/abs/2305.15336)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/01] **[Exploring AI Ethics of ChatGPT: A Diagnostic Analysis](https://arxiv.org/abs/2301.12867)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
