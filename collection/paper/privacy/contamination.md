# C1. Contamination
- [2025/07] **[How Much Do Large Language Model Cheat on Evaluation? Benchmarking Overestimation under the One-Time-Pad-Based Framework](https://arxiv.org/abs/2507.19219)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800)
- [2025/05] **[How Can I Publish My LLM Benchmark Without Giving the True Answers Away?](https://arxiv.org/abs/2505.18102)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800)
- [2024/06] **[LiveBench: A Challenging, Contamination-Free LLM Benchmark](https://arxiv.org/abs/2406.19314)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800)
- [2024/06] **[VarBench: Robust Language Model Benchmarking Through Dynamic Variable Perturbation](https://arxiv.org/abs/2406.17681)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800)
- [2024/06] **[Benchmark Data Contamination of Large Language Models: A Survey](https://arxiv.org/abs/2406.04244v1)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Survey](https://img.shields.io/badge/Survey-87b800)
- [2024/06] **[DICE: Detecting In-distribution Contamination in LLM's Fine-tuning Phase for Math Reasoning](https://arxiv.org/abs/2406.04197)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/THU-KEG/DICE) ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/04] **[Benchmarking Benchmark Leakage in Large Language Models](https://arxiv.org/abs/2404.18824)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Quantifying Contamination in Evaluating Code Generation Capabilities of Language Models](https://arxiv.org/abs/2403.04811)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Private Benchmarking to Prevent Contamination and Improve Comparative Evaluation of LLMs](https://arxiv.org/abs/2403.00393)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Benchmark](https://img.shields.io/badge/Benchmark-87b800)
- [2024/02] **[Leak, Cheat, Repeat: Data Contamination and Evaluation Malpractices in Closed-Source LLMs](https://arxiv.org/abs/2402.03927)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/01] **[KoLA: Carefully Benchmarking World Knowledge of Large Language Models](https://openreview.net/forum?id=AqN23oqraW)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://kola.xlore.cn/) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Proving Test Set Contamination for Black-Box Language Models](https://openreview.net/forum?id=KS8mIvetg2)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24_(Oral)](https://img.shields.io/badge/ICLR'24_(Oral)-f1b800)
- [2023/09] **[Time Travel in LLMs: Tracing Data Contamination in Large Language Models](https://openreview.net/forum?id=2Rwq6c3tvr)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24_(Spotlight)](https://img.shields.io/badge/ICLR'24_(Spotlight)-f1b800)
- [2023/09] **[To the Cutoff... and Beyond? A Longitudinal Perspective on LLM Data Contamination](https://openreview.net/forum?id=m2NVG4Htxs)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[DyVal: Graph-informed Dynamic Evaluation of Large Language Models](https://openreview.net/forum?id=gjfOL9z5Xr)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24_(Spotlight)](https://img.shields.io/badge/ICLR'24_(Spotlight)-f1b800)
