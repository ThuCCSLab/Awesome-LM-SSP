# C6. Privacy-Preserving Computation
- [2025/03] **[Token-Level Privacy in Large Language Models](https://arxiv.org/abs/2503.03652)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/03] **[PriFFT: Privacy-preserving Federated Fine-tuning of Large Language Models via Function Secret Sharing](https://arxiv.org/abs/2503.03146)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[RAPID: Retrieval Augmented Training of Differentially Private Diffusion Models](https://arxiv.org/abs/2502.12794)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/02] **[Secure Transformer Inference Made Non-interactive](https://www.ndss-symposium.org/ndss-paper/secure-transformer-inference-made-non-interactive/)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![NDSS'25](https://img.shields.io/badge/NDSS'25-f1b800)
- [2025/02] **[SHAFT: Secure, Handy, Accurate and Fast Transformer Inference](https://www.ndss-symposium.org/ndss-paper/shaft-secure-handy-accurate-and-fast-transformer-inference/)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![NDSS'25](https://img.shields.io/badge/NDSS'25-f1b800)
- [2025/02] **[A New PPML Paradigm for Quantized Models](https://www.ndss-symposium.org/ndss-paper/a-new-ppml-paradigm-for-quantized-models/)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![NDSS'25](https://img.shields.io/badge/NDSS'25-f1b800)
- [2025/02] **[Generating Privacy-Preserving Personalized Advice with Zero-Knowledge Proofs and LLMs](https://arxiv.org/abs/2502.06425)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[PM-MOE: Mixture of Experts on Private Model Parameters for Personalized Federated Learning](https://arxiv.org/abs/2502.00354)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Activation Approximations Can Incur Safety Vulnerabilities Even in Aligned LLMs: Comprehensive Analysis and Defense](https://arxiv.org/abs/2502.00840)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[SecPE: Secure Prompt Ensembling for Private and Robust Large Language Models](https://arxiv.org/abs/2502.00847)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Encrypted Large Model Inference: The Equivariant Encryption Paradigm](https://arxiv.org/abs/2502.01013)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/01] **[Differentially Private Steering for LLM Alignment](https://arxiv.org/abs/2501.18532)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'25](https://img.shields.io/badge/ICLR'25-f1b800)
- [2025/01] **[Scaling Laws for Differentially Private Language Models](https://arxiv.org/abs/2501.18914)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/01] **[Trusted Machine Learning Models Unlock Private Inference for Problems Currently Infeasible with Cryptography](https://arxiv.org/abs/2501.08970)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/01] **[MPCache: MPC-Friendly KV Cache Eviction for Efficient Private Large Language Model Inference](https://arxiv.org/abs/2501.06807)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/01] **[Practical Secure Inference Algorithm for Fine-tuned Large Language Model Based on Fully Homomorphic Encryption](https://arxiv.org/abs/2501.01672)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/12] **[RAG with Differential Privacy ](https://arxiv.org/abs/2412.19291)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2024/12] **[DR-Encoder: Encode Low-rank Gradients with Random Prior for Large Language Models Differentially Privately](https://arxiv.org/abs/2412.17053)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/12] **[Large Language Model Federated Learning with Blockchain and Unlearning for Cross-Organizational Collaboration](https://arxiv.org/abs/2412.13551)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/12] **[RemoteRAG: A Privacy-Preserving LLM Cloud RAG Service](https://arxiv.org/abs/2412.12775)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2024/12] **[Federated In-Context LLM Agent Learning](https://arxiv.org/abs/2412.08054)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/12] **[Privacy-Preserving Large Language Models: Mechanisms, Applications, and Future Directions](https://arxiv.org/abs/2412.06113)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/12] **[Privacy-Preserving Retrieval Augmented Generation with Differential Privacy](https://arxiv.org/abs/2412.04697)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2024/12] **[TruncFormer: Private LLM Inference Using Only Truncations](https://arxiv.org/abs/2412.01042)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[Preempting Text Sanitization Utility in Resource-Constrained Privacy-Preserving LLM Interactions](https://arxiv.org/abs/2411.11521)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[OML: Open, Monetizable, and Loyal AI](https://arxiv.org/abs/2411.03887)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[PipeLLM: Fast and Confidential Large Language Model Services with Speculative Pipelined Encryption](https://arxiv.org/abs/2411.03357)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ASPLOS'25](https://img.shields.io/badge/ASPLOS'25-f1b800)
- [2024/11] **[A Practical and Privacy-Preserving Framework for Real-World Large Language Model Services](https://arxiv.org/abs/2411.01471)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[SVIP: Towards Verifiable Inference of Open-source Large Language Models](https://arxiv.org/abs/2410.22307)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[LanFL: Differentially Private Federated Learning with Large Language Models using Synthetic Samples](https://arxiv.org/abs/2410.19114)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[PAPILLON: PrivAcy Preservation from Internet-based and Local Language MOdel ENsembles](https://arxiv.org/abs/2410.17127)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[FedSpaLLM: Federated Pruning of Large Language Models](https://arxiv.org/abs/2410.14852)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[AERO: Softmax-Only LLMs for Efficient Private Inference](https://arxiv.org/abs/2410.13060)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[FRAG: Toward Federated Vector Database Management for Collaborative and Secure Retrieval-Augmented Generation](https://arxiv.org/abs/2410.13272)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2024/10] **[Rescriber: Smaller-LLM-Powered User-Led Data Minimization for Navigating Privacy Trade-offs in LLM-Based Conversational Agent](https://arxiv.org/abs/2410.11876)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Data-adaptive Differentially Private Prompt Synthesis for In-Context Learning](https://arxiv.org/abs/2410.12085)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Reconstruction of Differentially Private Text Sanitization via Large Language Models](https://arxiv.org/abs/2410.12443)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Privately Learning from Graphs with Applications in Fine-tuning Large Language Models](https://arxiv.org/abs/2410.08299)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Fine-Tuning Language Models with Differential Privacy through Adaptive Noise Allocation](https://arxiv.org/abs/2410.02912)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Adaptively Private Next-Token Prediction of Large Language Models](https://arxiv.org/abs/2410.02016)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Encryption-Friendly LLM Architecture](https://arxiv.org/abs/2410.02486)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'25](https://img.shields.io/badge/ICLR'25-f1b800)
- [2024/10] **[PrivTuner with Homomorphic Encryption and LoRA: A P3EFT Scheme for Privacy-Preserving Parameter-Efficient Fine-Tuning of AI Foundation Models](https://arxiv.org/abs/2410.00433)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Secure Multiparty Generative AI](https://arxiv.org/abs/2409.19120)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Confidential Prompting: Protecting User Prompts from Cloud LLM Providers](https://arxiv.org/abs/2409.19134)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/08] **[Learning Differentially Private Diffusion Models via Stochastic Adversarial Distillation](https://arxiv.org/abs/2408.14738)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/08] **[SecFormer: Fast and Accurate Privacy-Preserving Inference for Transformer Models via SMPC](https://aclanthology.org/2024.findings-acl.790/)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL'24_(Findings)](https://img.shields.io/badge/ACL'24_(Findings)-f1b800)
- [2024/08] **[Towards Privacy-Aware Sign Language Translation at Scale](https://aclanthology.org/2024.acl-long.467/)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![ACL'24](https://img.shields.io/badge/ACL'24-f1b800)
- [2024/08] **[Casper: Prompt Sanitization for Protecting User Privacy in Web-Based Large Language Models](https://arxiv.org/abs/2408.07004)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/08] **[MPC-Minimized Secure LLM Inference](https://arxiv.org/abs/2408.03561)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Fine-Tuning Large Language Models with User-Level Differential Privacy](https://arxiv.org/abs/2407.07737)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[IncogniText: Privacy-enhancing Conditional Text Anonymization via LLM-based Private Attribute Randomization](https://arxiv.org/abs/2407.02956)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[ObfuscaTune: Obfuscated Offsite Fine-tuning and Inference of Proprietary LLMs on Private Datasets](https://arxiv.org/abs/2407.02960)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Safely Learning with Private Data: A Federated Learning Framework for Large Language Model](https://arxiv.org/abs/2406.14898)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Mind the Privacy Unit! User-Level Differential Privacy for Language Model Fine-Tuning](https://arxiv.org/abs/2406.14322)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[The Fire Thief Is Also the Keeper: Balancing Usability and Privacy in Prompts](https://arxiv.org/abs/2406.14318)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Promoting Data and Model Privacy in Federated Learning through Quantized LoRA](https://arxiv.org/abs/2406.10976)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[MemDPT: Differential Privacy for Memory Efficient Language Models](https://arxiv.org/abs/2406.11087)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Efficient Differentially Private Fine-Tuning of Diffusion Models](https://arxiv.org/abs/2406.05257)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/06] **[PrE-Text: Training Language Models on Private Federated Data in the Age of LLMs](https://arxiv.org/abs/2406.02958)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Differentially Private Fine-Tuning of Diffusion Models](https://arxiv.org/abs/2406.01355)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/06] **[PrivacyRestore: Privacy-Preserving Inference in Large Language Models via Privacy Removal and Restoration](https://arxiv.org/abs/2406.01394)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[No Free Lunch Theorem for Privacy-Preserving LLM Inference](https://arxiv.org/abs/2405.20681)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[PermLLM: Private Inference of Large Language Models within 3 Seconds under WAN](https://arxiv.org/abs/2405.18744)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[LMO-DP: Optimizing the Randomization Mechanism for Differentially Private Fine-Tuning (Large) Language Models](https://arxiv.org/abs/2405.18776)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Delving into Differentially Private Transformer](https://arxiv.org/abs/2405.18194)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICML'24](https://img.shields.io/badge/ICML'24-f1b800)
- [2024/05] **[Locally Differentially Private In-Context Learning](https://arxiv.org/abs/2405.04032)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![LREC-Coling’24](https://img.shields.io/badge/LREC-Coling’24-f1b800)
- [2024/04] **[zkLLM: Zero Knowledge Proofs for Large Language Models](https://arxiv.org/abs/2404.16109)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![CCS'24](https://img.shields.io/badge/CCS'24-f1b800)
- [2024/03] **[Efficient Language Model Architectures for Differentially Private Federated Learning](https://arxiv.org/abs/2403.08100)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[A Framework for Cost-Effective and Self-Adaptive LLM Shaking and Recovery Mechanism](https://arxiv.org/abs/2403.07283)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[DP-TabICL: In-Context Learning with Differentially Private Tabular Data](https://arxiv.org/abs/2403.05681)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Privacy-Preserving Diffusion Model Using Homomorphic Encryption](https://arxiv.org/abs/2403.05794)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/02] **[LLM-based Privacy Data Augmentation Guided by Knowledge Distillation with a Distribution Tutor for Medical Text Classification](https://arxiv.org/abs/2402.16515)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Privacy-Preserving Language Model Inference with Instance Obfuscation](https://arxiv.org/abs/2402.08227)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[PromptCrypt: Prompt Encryption for Secure Communication with Large Language Models](https://arxiv.org/abs/2402.05868)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/agiresearch/PromptCrypt) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2023/10] **[BumbleBee: Secure Two-party Inference Framework for Large Transformers](https://eprint.iacr.org/2023/1678)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![NDSS'25](https://img.shields.io/badge/NDSS'25-f1b800)
- [2023/10] **[Locally Differentially Private Document Generation Using Zero Shot Prompting](https://arxiv.org/abs/2310.16111)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![EMNLP'23_(Findings)](https://img.shields.io/badge/EMNLP'23_(Findings)-f1b800)
- [2023/09] **[Differentially Private Synthetic Data via Foundation Model APIs 1: Images](https://openreview.net/forum?id=YEhQs8POIo)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[DP-OPT: Make Large Language Model Your Differentially-Private Prompt Engineer](https://openreview.net/forum?id=Ifz3IgsEPX)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24_(Spotlight)](https://img.shields.io/badge/ICLR'24_(Spotlight)-f1b800)
- [2023/09] **[Enhancing Small Medical Learners with Privacy-preserving Contextual Prompting](https://openreview.net/forum?id=ztpy1gsUpT)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Improving LoRA in Privacy-preserving Federated Learning](https://openreview.net/forum?id=NLPzL6HWNl)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Privacy-Preserving In-Context Learning for Large Language Models](https://openreview.net/forum?id=x4OPJ7lHVU)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation](https://openreview.net/forum?id=oZtt0pRnOl)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Privately Aligning Language Models with Reinforcement Learning](https://openreview.net/forum?id=3d0OmYTNui)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[DP-Forward: Fine-tuning and Inference on Language Models with Differential Privacy in Forward Pass](https://arxiv.org/abs/2309.06746)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800) ![CCS'23](https://img.shields.io/badge/CCS'23-f1b800)
- [2023/08] **[SIGMA: Secure GPT Inference with Function Secret Sharing](https://eprint.iacr.org/2023/1269)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/07] **[CipherGPT: Secure Two-Party GPT Inference](https://eprint.iacr.org/2023/1147)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/05] **[Privacy-Preserving Prompt Tuning for Large Language Model Services](https://arxiv.org/abs/2305.06212)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/05] **[Privacy-Preserving Recommender Systems with Synthetic Query Generation using Differentially Private Large Language Models](https://arxiv.org/abs/2305.05973)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2022/10] **[EW-Tune: A Framework for Privately Fine-Tuning Large Language Models with Differential Privacy](https://arxiv.org/abs/2210.15042)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICDM'22_(Workshops)](https://img.shields.io/badge/ICDM'22_(Workshops)-f1b800)
