# C2. Copyright
- [2025/04] **[GenPTW: In-Generation Image Watermarking for Provenance Tracing and Tamper Localization](https://arxiv.org/abs/2504.19567)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/04] **[VideoMark: A Distortion-Free Robust Watermarking Framework for Video Diffusion Models](https://arxiv.org/abs/2504.16359)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Video](https://img.shields.io/badge/Video-87b800)
- [2025/04] **[What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale](https://arxiv.org/abs/2504.14815)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/04] **[Gaussian Shading++: Rethinking the Realistic Deployment Challenge of Performance-Lossless Image Watermark for Diffusion Models](https://arxiv.org/abs/2504.15026)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/04] **[Protecting Your Voice: Temporal-aware Robust Watermarking](https://arxiv.org/abs/2504.14832)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Speech](https://img.shields.io/badge/Speech-87b800)
- [2025/04] **[SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank Adaptation](https://arxiv.org/abs/2504.15035)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Speech](https://img.shields.io/badge/Speech-87b800)
- [2025/04] **[ArtistAuditor: Auditing Artist Style Pirate in Text-to-Image Generation Models](https://arxiv.org/abs/2504.13061)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![WWW'25](https://img.shields.io/badge/WWW'25-f1b800)
- [2025/04] **[PCDiff: Proactive Control for Ownership Protection in Diffusion Models with Watermark Compatibility ](https://arxiv.org/abs/2504.11774)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/04] **[PT-Mark: Invisible Watermarking for Text-to-image Diffusion Models via Semantic-aware Pivotal Tuning](https://arxiv.org/abs/2504.10853)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/04] **[Defending LLM Watermarking Against Spoofing Attacks with Contrastive Representation Learning](https://arxiv.org/abs/2504.06575)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[Detection Limits and Statistical Separability of Tree Ring Watermarks in Rectified Flow-based Text-to-Image Generation Models](https://arxiv.org/abs/2504.03850)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/04] **[Watermarking for AI Content Detection: A Review on Text, Visual, and Audio Modalities](https://arxiv.org/abs/2504.03765)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/04] **[How does Watermarking Affect Visual Language Models in Document Understanding?](https://arxiv.org/abs/2504.01048)** ![VLM](https://img.shields.io/badge/VLM-c7688b)
- [2025/03] **[Protecting Your Video Content: Disrupting Automated Video-based LLM Annotations](https://arxiv.org/abs/2503.21824)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![video](https://img.shields.io/badge/video-87b800) ![CVPR'25](https://img.shields.io/badge/CVPR'25-f1b800)
- [2025/03] **[Imperceptible but Forgeable: Practical Invisible Watermark Forgery via Diffusion Models](https://arxiv.org/abs/2503.22330)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/03] **[CEFW: A Comprehensive Evaluation Framework for Watermark in Large Language Models](https://arxiv.org/abs/2503.20802)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/03] **[SEAL: Semantic Aware Image Watermarking ](https://arxiv.org/abs/2503.12172)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/03] **[Towards A Correct Usage of Cryptography in Semantic Watermarks for Diffusion Models](https://arxiv.org/abs/2503.11404)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![_WMark@ICLR‘25](https://img.shields.io/badge/_WMark@ICLR‘25-f1b800)
- [2025/03] **[Mark Your LLM: Detecting the Misuse of Open-Source Large Language Models via Watermarking](https://arxiv.org/abs/2503.04636)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/03] **[Robust Data Watermarking in Language Models by Injecting Fictitious Knowledge](https://arxiv.org/abs/2503.04036)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/03] **[The Challenge of Identifying the Origin of Black-Box Large Language Models](https://arxiv.org/abs/2503.04332)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Tracking the Copyright of Large Vision-Language Models through Parameter Learning Adversarial Images](https://arxiv.org/abs/2502.16593)** ![VLM](https://img.shields.io/badge/VLM-c7688b) ![ICLR'25](https://img.shields.io/badge/ICLR'25-f1b800)
- [2025/02] **[Merger-as-a-Stealer: Stealing Targeted PII from Aligned LLMs with Model Merging](https://arxiv.org/abs/2502.16094)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Marking Code Without Breaking It: Code Watermarking for Detecting LLM-Generated Code](https://arxiv.org/abs/2502.18851)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Obliviate: Efficient Unmemorization for Protecting Intellectual Property in Large Language Models](https://arxiv.org/abs/2502.15010)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Secure and Efficient Watermarking for Latent Diffusion Models in Model Distribution Scenarios](https://arxiv.org/abs/2502.13345)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/02] **[Image Watermarks are Removable Using Controllable Regeneration from Clean Noise](https://arxiv.org/abs/2410.05470)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICLR'25](https://img.shields.io/badge/ICLR'25-f1b800)
- [2025/02] **[SWA-LDM: Toward Stealthy Watermarks for Latent Diffusion Models](https://arxiv.org/abs/2502.10495)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/02] **[Towards Watermarking of Open-Source LLMs](https://arxiv.org/abs/2502.10525)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Dataset Protection via Watermarked Canaries in Retrieval-Augmented LLMs](https://arxiv.org/abs/2502.10673)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2025/02] **[Scalable Fingerprinting of Large Language Models](https://arxiv.org/abs/2502.07760)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[DERMARK: A Dynamic, Efficient and Robust Multi-bit Watermark for Large Language Models](https://arxiv.org/abs/2502.05213)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[SimMark: A Robust Sentence-Level Similarity-Based Watermarking Algorithm for Large Language Models](https://arxiv.org/abs/2502.02787)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Robust and Secure Code Watermarking for Large Language Models via ML/Crypto Codesign](https://arxiv.org/abs/2502.02068)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/02] **[Model Provenance Testing for Large Language Models](https://arxiv.org/abs/2502.00706)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/01] **[PSyDUCK: Training-Free Steganography for Latent Diffusion ](https://arxiv.org/abs/2501.19172)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2025/01] **[LoRAGuard: An Effective Black-box Watermarking Approach for LoRAs](https://arxiv.org/abs/2501.15478)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/01] **[GaussMark: A Practical Approach for Structural Watermarking of Language Models](https://arxiv.org/abs/2501.13941)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/01] **[SEAL: Entangled White-box Watermarks on Low-Rank Adaptation](https://arxiv.org/abs/2501.09284)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2025/01] **[RAG-WM: An Efficient Black-Box Watermarking Approach for Retrieval-Augmented Generation of Large Language Models](https://arxiv.org/abs/2501.05249)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2025/01] **[SAT-LDM: Provably Generalizable Image Watermarking for Latent Diffusion Models with Self-Augmented Training](https://arxiv.org/abs/2501.00463)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/12] **[ExpShield: Safeguarding Web Text from Unauthorized Crawling and Language Modeling Exploitation](https://arxiv.org/abs/2412.21123)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/12] **[Copyright-Protected Language Generation via Adaptive Model Fusion](https://arxiv.org/abs/2412.06619)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/12] **[Black-Box Forgery Attacks on Semantic Watermarks for Diffusion Models](https://arxiv.org/abs/2412.03283)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/11] **[Do LLMs Know to Respect Copyright Notice?](https://aclanthology.org/2024.emnlp-main.1147.pdf)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![EMNLP'24](https://img.shields.io/badge/EMNLP'24-f1b800)
- [2024/11] **[SoK: Watermarking for AI-Generated Content](https://arxiv.org/abs/2411.18479)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![SoK](https://img.shields.io/badge/SoK-87b800)
- [2024/11] **[CDI: Copyrighted Data Identification in Diffusion Models](https://arxiv.org/abs/2411.12858)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/11] **[CopyrightMeter: Revisiting Copyright Protection in Text-to-image Models](https://arxiv.org/abs/2411.13144)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/11] **[WaterPark: A Robustness Assessment of Language Model Watermarking](https://arxiv.org/abs/2411.13425)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[One Prompt to Verify Your Models: Black-Box Text-to-Image Models Verification via Non-Transferable Adversarial Attacks](https://arxiv.org/abs/2410.22725)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/11] **[Debiasing Watermarks for Large Language Models via Maximal Coupling](https://arxiv.org/abs/2411.11203)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[CLUE-MARK: Watermarking Diffusion Models using CLWE](https://arxiv.org/abs/2411.11434)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/11] **[SoK: On the Role and Future of AIGC Watermarking in the Era of Gen-AI](https://arxiv.org/abs/2411.11478)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[Conceptwm: A Diffusion Model Watermark for Concept Protection](https://arxiv.org/abs/2411.11688)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/11] **[LLM App Squatting and Cloning](https://arxiv.org/abs/2411.07518)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[InvisMark: Invisible and Robust Watermarking for AI-generated Image Provenance](https://arxiv.org/abs/2411.07795)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[Watermarking Language Models through Language Models](https://arxiv.org/abs/2411.05091)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[Revisiting the Robustness of Watermarking to Paraphrasing Attacks](https://arxiv.org/abs/2411.05277)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/11] **[ROBIN: Robust and Invisible Watermarks for Diffusion Models with Adversarial Optimization](https://arxiv.org/abs/2411.03862)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/10] **[Embedding Watermarks in Diffusion Process for Model Intellectual Property Protection](https://arxiv.org/abs/2410.22445)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/10] **[Shallow Diffuse: Robust and Invisible Watermarking through Low-Dimensional Subspaces in Diffusion Models](https://arxiv.org/abs/2410.21088)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/10] **[Inevitable Trade-off between Watermark Strength and Speculative Sampling Efficiency for Language Models](https://arxiv.org/abs/2410.20418)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Watermarking Large Language Models and the Generated Content: Opportunities and Challenges](https://arxiv.org/abs/2410.19096)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Robust Watermarking Using Generative Priors Against Image Editing: From Benchmarking to Advances](https://arxiv.org/abs/2410.18775)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/10] **[Provably Robust Watermarks for Open-Source Language Models](https://arxiv.org/abs/2410.18861)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[REEF: Representation Encoding Fingerprints for Large Language Models](https://arxiv.org/abs/2410.14273)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[CoreGuard: Safeguarding Foundational Capabilities of LLMs Against Model Stealing in Edge Deployment](https://arxiv.org/abs/2410.13903)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[NSmark: Null Space Based Black-box Watermarking Defense Framework for Pre-trained Language Models](https://arxiv.org/abs/2410.13907)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[UTF:Undertrained Tokens as Fingerprints A Novel Approach to LLM Identification](https://arxiv.org/abs/2410.12318)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[FreqMark: Frequency-Based Watermark for Sentence-Level Detection of LLM-Generated Text](https://arxiv.org/abs/2410.10876)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[MergePrint: Robust Fingerprinting against Merging Large Language Models](https://arxiv.org/abs/2410.08604)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[An undetectable watermark for generative image models ](https://arxiv.org/abs/2410.07369)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/10] **[WAPITI: A Watermark for Finetuned Open-Source LLMs](https://arxiv.org/abs/2410.06467)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Signal Watermark on Large Language Models](https://arxiv.org/abs/2410.06545)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Ward: Provable RAG Dataset Inference via LLM Watermarks](https://arxiv.org/abs/2410.03537)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![RAG](https://img.shields.io/badge/RAG-87b800)
- [2024/10] **[Universally Optimal Watermarking Schemes for LLMs: from Theory to Practice](https://arxiv.org/abs/2410.02890)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Can Watermarked LLMs be Identified by Users via Crafted Prompts?](https://arxiv.org/abs/2410.03168)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[A Watermark for Black-Box Language Models](https://arxiv.org/abs/2410.02099)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Optimizing Adaptive Attacks against Content Watermarks for Language Models](https://arxiv.org/abs/2410.02440)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/10] **[Discovering Clues of Spoofed LM Watermarks](https://arxiv.org/abs/2410.02693)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Dormant: Defending against Pose-driven Human Image Animation](https://arxiv.org/abs/2409.14424)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/Manu21JC/Dormant) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/09] **[A Certified Robust Watermark For Large Language Models](https://arxiv.org/abs/2409.19708)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Multi-Designated Detector Watermarking for Language Models](https://arxiv.org/abs/2409.17518)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Measuring Copyright Risks of Large Language Model via Partial Information Probing](https://arxiv.org/abs/2409.13831)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[Towards Effective User Attribution for Latent Diffusion Models via Watermark-Informed Blending](https://arxiv.org/abs/2409.10958)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/09] **[PersonaMark: Personalized LLM watermarking for model protection and user attribution](https://arxiv.org/abs/2409.09739)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/09] **[FP-VEC: Fingerprinting Large Language Models via Efficient Vector Addition](https://arxiv.org/abs/2409.08846)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/08] **[Watermarking Techniques for Large Language Models: A Survey](https://arxiv.org/abs/2409.00089)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Survey](https://img.shields.io/badge/Survey-87b800)
- [2024/08] **[MCGMark: An Encodable and Robust Online Watermark for LLM-Generated Malicious Code](https://arxiv.org/abs/2408.01354)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![codeGen](https://img.shields.io/badge/codeGen-87b800)
- [2024/08] **[Robustness of Watermarking on Text-to-Image Diffusion Models ](https://arxiv.org/abs/2408.02035)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/08] **[Hide and Seek: Fingerprinting Large Language Models with Evolutionary Learning](https://arxiv.org/abs/2408.02871)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Strong Copyright Protection for Language Models via Adaptive Model Fusion](https://arxiv.org/abs/2407.20105)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[LLMmap: Fingerprinting For Large Language Models](https://arxiv.org/abs/2407.15847)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[SLIP: Securing LLMs IP Using Weights Decomposition](https://arxiv.org/abs/2407.10886)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Hey, That's My Model! Introducing Chain & Hash, An LLM Fingerprinting Technique](https://arxiv.org/abs/2407.10887)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Building Intelligence Identification System via Large Language Model Watermarking: A Survey and Beyond](https://arxiv.org/abs/2407.11100)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Less is More: Sparse Watermarking in LLMs with Enhanced Text Quality](https://arxiv.org/abs/2407.13803)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[On Evaluating The Performance of Watermarked Machine-Generated Texts Under Adversarial Attacks](https://arxiv.org/abs/2407.04794)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[Waterfall: Framework for Robust and Scalable Text Watermarking](https://arxiv.org/abs/2407.04411)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/07] **[A Fingerprint for Large Language Models](https://arxiv.org/abs/2407.01235)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[AIGC-Chain: A Blockchain-Enabled Full Lifecycle Recording System for AIGC Product Copyright Management](https://arxiv.org/abs/2406.14966)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Blockchain](https://img.shields.io/badge/Blockchain-87b800)
- [2024/06] **[PID: Prompt-Independent Data Protection Against Latent Diffusion Models](https://arxiv.org/abs/2406.15305)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICML'24](https://img.shields.io/badge/ICML'24-f1b800)
- [2024/06] **[PostMark: A Robust Blackbox Watermark for Large Language Models](https://arxiv.org/abs/2406.14517)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[EnTruth: Enhancing the Traceability of Unauthorized Dataset Usage in Text-to-image Diffusion Models with Minimal and Robust Alterations](https://arxiv.org/abs/2406.13933)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/06] **[Adversarial Perturbations Cannot Reliably Protect Artists From Generative AI](https://arxiv.org/abs/2406.12027)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/06] **[Hiding Text in Large Language Models: Introducing Unconditional Token Forcing Confusion](https://arxiv.org/abs/2406.02481)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Bileve: Securing Text Provenance in Large Language Models Against Spoofing with Bi-level Signature](https://arxiv.org/abs/2406.01946)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/06] **[Edit Distance Robust Watermarks for Language Models](https://arxiv.org/abs/2406.02633)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Black-Box Detection of Language Model Watermarks](https://arxiv.org/abs/2405.20777)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Large Language Model Watermark Stealing With Mixed Integer Programming](https://arxiv.org/abs/2405.19677)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[FreezeAsGuard: Mitigating Illegal Adaptation of Diffusion Models via Selective Tensor Freezing](https://arxiv.org/abs/2405.17472)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[A Watermark for Low-entropy and Unbiased Generation in Large Language Models](https://arxiv.org/abs/2405.14604)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[Enhancing Watermarked Language Models to Identify Users](https://arxiv.org/abs/2405.11109)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[AquaLoRA: Toward White-box Protection for Customized Stable Diffusion Models via Watermark LoRA](https://arxiv.org/abs/2405.11135)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[Stylometric Watermarks for Large Language Models](https://arxiv.org/abs/2405.08400)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[UnMarker: A Universal Attack on Defensive Watermarking](https://arxiv.org/abs/2405.08363)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[Stable Signature is Unstable: Removing Image Watermark from Diffusion Models](https://arxiv.org/abs/2405.07145)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[Adaptive and robust watermark against model extraction attack](https://arxiv.org/abs/2405.02365)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[ProFLingo: A Fingerprinting-based Copyright Protection Scheme for Large Language Models](https://arxiv.org/abs/2405.02466)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/05] **[DiffuseTrace: A Transparent and Flexible Watermarking Scheme for Latent Diffusion Model](https://arxiv.org/abs/2405.02696)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/05] **[Lazy Layers to Make Fine-Tuned Diffusion Models More Traceable](https://arxiv.org/abs/2405.00466)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/04] **[Disguised Copyright Infringement of Latent Diffusion Model](https://arxiv.org/abs/2404.06737)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/04] **[Gaussian Shading: Provable Performance-Lossless Image Watermarking for Diffusion Models](https://arxiv.org/abs/2404.04956)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![CVPR'24](https://img.shields.io/badge/CVPR'24-f1b800)
- [2024/04] **[Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging](https://arxiv.org/abs/2404.05188)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![LAMPS@CCS‘24](https://img.shields.io/badge/LAMPS@CCS‘24-f1b800) ![Best Paper](https://img.shields.io/badge/Best_paper-ff0000)
- [2024/04] **[A Training-Free Plug-and-Play Watermark Framework for Stable Diffusion](https://arxiv.org/abs/2404.05607)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/04] **[Topic-based Watermarks for LLM-Generated Text](https://arxiv.org/abs/2404.02138)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/04] **[A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules](https://arxiv.org/abs/2404.01245)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[RAW: A Robust and Agile Plug-and-Play Watermark Framework for AI-Generated Images with Provable Guarantees](https://arxiv.org/abs/2403.18774)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/03] **[Is Watermarking LLM-Generated Code Robust?](https://arxiv.org/abs/2403.17983)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![codeGen](https://img.shields.io/badge/codeGen-87b800)
- [2024/03] **[Ghost Sentence: A Tool for Everyday Users to Copyright Data from Large Language Models](https://arxiv.org/abs/2403.15740)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Bypassing LLM Watermarks with Color-Aware Substitutions](https://arxiv.org/abs/2403.14719)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[A Transfer Attack to Image Watermarks](https://arxiv.org/abs/2403.15365)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/03] **[An Entropy-based Text Watermarking Detection Method](https://arxiv.org/abs/2403.13485)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Duwak: Dual Watermarks in Large Language Models](https://arxiv.org/abs/2403.13000)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Towards Better Statistical Understanding of Watermarking LLMs](https://arxiv.org/abs/2403.13027)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Learning to Watermark LLM-generated Text via Reinforcement Learning](https://arxiv.org/abs/2403.10553)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[A Watermark-Conditioned Diffusion Model for IP Protection](https://arxiv.org/abs/2403.10893)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/03] **[Hufu: A Modality-Agnositc Watermarking System for Pre-Trained Transformers via Permutation Equivariance](https://arxiv.org/abs/2403.05842)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off](https://arxiv.org/abs/2403.04808)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Watermark Stealing in Large Language Models](https://arxiv.org/abs/2402.19361)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Token-Specific Watermarking with Enhanced Detectability and Semantic Coherence for Large Language Models](https://arxiv.org/abs/2402.18059)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[EmMark: Robust Watermarks for IP Protection of Embedded Quantized Large Language Models](https://arxiv.org/abs/2402.17938)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Generative Models are Self-Watermarked: Declaring Model Authentication through Re-Generation](https://arxiv.org/abs/2402.16889)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/02] **[Attacking LLM Watermarks by Exploiting Their Strengths](https://arxiv.org/abs/2402.16187)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning](https://arxiv.org/abs/2402.14883)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Watermarking Makes Language Models Radioactive](https://arxiv.org/abs/2402.14904)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models](https://arxiv.org/abs/2402.14007)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[A Survey of Text Watermarking in the Era of Large Language Models](https://arxiv.org/abs/2312.07913)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Survey](https://img.shields.io/badge/Survey-87b800)
- [2024/02] **[Proving membership in LLM pretraining data via data watermarks](https://arxiv.org/abs/2402.10892)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Resilient Watermarking for LLM-Generated Codes](https://arxiv.org/abs/2402.07518)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Permute-and-Flip: An optimally robust and watermarkable decoder for LLMs](https://arxiv.org/abs/2402.05864)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/XuandongZhao/pf-decoding) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Copyright Protection in Generative AI: A Technical Perspective ](https://arxiv.org/abs/2402.02333)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/01] **[Adaptive Text Watermark for Large Language Models](https://arxiv.org/abs/2401.13927)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/01] **[Instructional Fingerprinting of Large Language Models](https://arxiv.org/abs/2401.12255)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/01] **[Generative AI Has a Visual Plagiarism Problem](https://spectrum.ieee.org/midjourney-copyright)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Blog](https://img.shields.io/badge/Blog-f1b800)
- [2023/12] **[Human-Readable Fingerprint for Large Language Models](https://arxiv.org/abs/2312.04828)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/12] **[Mark My Words: Analyzing and Evaluating Language Model Watermarks](https://arxiv.org/abs/2312.00273)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/wagner-group/MarkMyWords) ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/11] **[WaterBench: Towards Holistic Evaluation of Watermarks for Large Language Models](https://arxiv.org/abs/2311.07138)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/THU-KEG/WaterBench) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ACL'24](https://img.shields.io/badge/ACL'24-f1b800)
- [2023/11] **[Towards More Effective Protection Against Diffusion-Based Mimicry with Score Distillation](https://arxiv.org/abs/2311.12832)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/xavihart/Diff-Protect) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/11] **[A Robust Semantics-based Watermark for Large Language Model against Paraphrasing](https://arxiv.org/abs/2311.08721)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/11] **[Protecting Intellectual Property of Large Language Model-Based Code Generation APIs via Watermarks](https://dl.acm.org/doi/abs/10.1145/3576915.3623120)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![CodeGen](https://img.shields.io/badge/CodeGen-87b800) ![CCS'23](https://img.shields.io/badge/CCS'23-f1b800)
- [2023/10] **[REMARK-LLM: A Robust and Efficient Watermarking Framework for Generative Large Language Models ](https://arxiv.org/abs/2310.12362)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![USENIX_Security'24](https://img.shields.io/badge/USENIX_Security'24-f1b800)
- [2023/10] **[Watermarking LLMs with Weight Quantization](https://arxiv.org/abs/2310.11237)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![EMNLP‘23_(Findings)](https://img.shields.io/badge/EMNLP‘23_(Findings)-f1b800)
- [2023/09] **[A Private Watermark for Large Language Models](https://openreview.net/forum?id=gMLQwKDY3N)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[A Semantic Invariant Robust Watermark for Large Language Models](https://openreview.net/forum?id=6p8lpe4MNf)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Provable Robust Watermarking for AI-Generated Text](https://openreview.net/forum?id=SsmT8aO45L)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore](https://openreview.net/forum?id=ruk0nyQPec)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24_(Spotlight)](https://img.shields.io/badge/ICLR'24_(Spotlight)-f1b800)
- [2023/08] **[PromptCARE: Prompt Copyright Protection by Watermark Injection and Verification](https://arxiv.org/abs/2308.02816)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/grasses/PromptCARE) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![S&P'24](https://img.shields.io/badge/S&P'24-f1b800)
- [2023/06] **[Generative Watermarking Against Unauthorized Subject-Driven Image Synthesis](https://arxiv.org/abs/2306.07754)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2023/05] **[Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust](https://arxiv.org/abs/2305.20030)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/YuxinWenRick/tree-ring-watermark) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![NeurIPS'23](https://img.shields.io/badge/NeurIPS'23-f1b800)
- [2023/05] **[Watermarking Diffusion Model](https://arxiv.org/abs/2305.12502)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2023/03] **[A Recipe for Watermarking Diffusion Models](https://arxiv.org/abs/2303.10137)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/yunqing-me/WatermarkDM) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2023/02] **[Glaze: Protecting Artists from Style Mimicry by Text-to-Image Models](https://arxiv.org/abs/2302.04222)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://glaze.cs.uchicago.edu/) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![USENIX_Security'23](https://img.shields.io/badge/USENIX_Security'23-f1b800) ![Best Paper](https://img.shields.io/badge/Best_paper-ff0000)
- [2023/01] **[A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](github.com/jwkirchenbauer/lm-watermarking) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICML'23](https://img.shields.io/badge/ICML'23-f1b800) ![Best Paper](https://img.shields.io/badge/Best_paper-ff0000)
