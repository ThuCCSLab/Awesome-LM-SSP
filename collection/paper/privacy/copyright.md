# C2. Copyright
- [2024/03] **[An Entropy-based Text Watermarking Detection Method](https://arxiv.org/abs/2403.13485)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Duwak: Dual Watermarks in Large Language Models](https://arxiv.org/abs/2403.13000)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Towards Better Statistical Understanding of Watermarking LLMs](https://arxiv.org/abs/2403.13027)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[Learning to Watermark LLM-generated Text via Reinforcement Learning](https://arxiv.org/abs/2403.10553)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[A Watermark-Conditioned Diffusion Model for IP Protection](https://arxiv.org/abs/2403.10893)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/03] **[Hufu: A Modality-Agnositc Watermarking System for Pre-Trained Transformers via Permutation Equivariance](https://arxiv.org/abs/2403.05842)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/03] **[WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off](https://arxiv.org/abs/2403.04808)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Watermark Stealing in Large Language Models](https://arxiv.org/abs/2402.19361)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Token-Specific Watermarking with Enhanced Detectability and Semantic Coherence for Large Language Models](https://arxiv.org/abs/2402.18059)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[EmMark: Robust Watermarks for IP Protection of Embedded Quantized Large Language Models](https://arxiv.org/abs/2402.17938)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Generative Models are Self-Watermarked: Declaring Model Authentication through Re-Generation](https://arxiv.org/abs/2402.16889)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/02] **[Attacking LLM Watermarks by Exploiting Their Strengths](https://arxiv.org/abs/2402.16187)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[Double-I Watermark: Protecting Model Copyright for LLM Fine-tuning](https://arxiv.org/abs/2402.14883)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Watermarking Makes Language Models Radioactive](https://arxiv.org/abs/2402.14904)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Can Watermarks Survive Translation? On the Cross-lingual Consistency of Text Watermark for Large Language Models](https://arxiv.org/abs/2402.14007)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/02] **[A Survey of Text Watermarking in the Era of Large Language Models](https://arxiv.org/abs/2312.07913)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Survey](https://img.shields.io/badge/Survey-87b800)
- [2024/02] **[Proving membership in LLM pretraining data via data watermarks](https://arxiv.org/abs/2402.10892)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Resilient Watermarking for LLM-Generated Codes](https://arxiv.org/abs/2402.07518)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Permute-and-Flip: An optimally robust and watermarkable decoder for LLMs](https://arxiv.org/abs/2402.05864)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/XuandongZhao/pf-decoding) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Defense](https://img.shields.io/badge/Defense-87b800)
- [2024/02] **[Copyright Protection in Generative AI: A Technical Perspective ](https://arxiv.org/abs/2402.02333)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2024/01] **[Adaptive Text Watermark for Large Language Models](https://arxiv.org/abs/2401.13927)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/01] **[Instructional Fingerprinting of Large Language Models](https://arxiv.org/abs/2401.12255)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2024/01] **[Generative AI Has a Visual Plagiarism Problem](https://spectrum.ieee.org/midjourney-copyright)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![Blog](https://img.shields.io/badge/Blog-f1b800)
- [2023/12] **[Human-Readable Fingerprint for Large Language Models](https://arxiv.org/abs/2312.04828)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/12] **[Mark My Words: Analyzing and Evaluating Language Model Watermarks](https://arxiv.org/abs/2312.00273)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/wagner-group/MarkMyWords) ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/11] **[Towards More Effective Protection Against Diffusion-Based Mimicry with Score Distillation](https://arxiv.org/abs/2311.12832)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/xavihart/Diff-Protect) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/11] **[A Robust Semantics-based Watermark for Large Language Model against Paraphrasing](https://arxiv.org/abs/2311.08721)** ![LLM](https://img.shields.io/badge/LLM-589cf4)
- [2023/11] **[Protecting Intellectual Property of Large Language Model-Based Code Generation APIs via Watermarks](https://dl.acm.org/doi/abs/10.1145/3576915.3623120)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![CodeGen](https://img.shields.io/badge/CodeGen-87b800) ![CCS'23](https://img.shields.io/badge/CCS'23-f1b800)
- [2023/10] **[Watermarking LLMs with Weight Quantization](https://arxiv.org/abs/2310.11237)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![EMNLP‘23_(Findings)](https://img.shields.io/badge/EMNLP‘23_(Findings)-f1b800)
- [2023/09] **[A Private Watermark for Large Language Models](https://openreview.net/forum?id=gMLQwKDY3N)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[A Semantic Invariant Robust Watermark for Large Language Models](https://openreview.net/forum?id=6p8lpe4MNf)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[Provable Robust Watermarking for AI-Generated Text](https://openreview.net/forum?id=SsmT8aO45L)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24](https://img.shields.io/badge/ICLR'24-f1b800)
- [2023/09] **[SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore](https://openreview.net/forum?id=ruk0nyQPec)** ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICLR'24_(Spotlight)](https://img.shields.io/badge/ICLR'24_(Spotlight)-f1b800)
- [2023/08] **[PromptCARE: Prompt Copyright Protection by Watermark Injection and Verification](https://arxiv.org/abs/2308.02816)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/grasses/PromptCARE) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![S&P'24](https://img.shields.io/badge/S&P'24-f1b800)
- [2023/06] **[Generative Watermarking Against Unauthorized Subject-Driven Image Synthesis](https://arxiv.org/abs/2306.07754)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2023/05] **[Tree-Ring Watermarks: Fingerprints for Diffusion Images that are Invisible and Robust](https://arxiv.org/abs/2305.20030)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/YuxinWenRick/tree-ring-watermark) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4) ![NeurIPS'23](https://img.shields.io/badge/NeurIPS'23-f1b800)
- [2023/05] **[Watermarking Diffusion Model](https://arxiv.org/abs/2305.12502)** ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2023/03] **[A Recipe for Watermarking Diffusion Models](https://arxiv.org/abs/2303.10137)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://github.com/yunqing-me/WatermarkDM) ![Diffusion](https://img.shields.io/badge/Diffusion-a99cf4)
- [2023/02] **[Glaze: Protecting Artists from Style Mimicry by Text-to-Image Models](https://arxiv.org/abs/2302.04222)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](https://glaze.cs.uchicago.edu/) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![Security'23](https://img.shields.io/badge/Security'23-f1b800) ![Best Paper](https://img.shields.io/badge/Best_paper-ff0000)
- [2023/01] **[A Watermark for Large Language Models](https://arxiv.org/abs/2301.10226)** [<img src="https://github.com/FortAwesome/Font-Awesome/blob/6.x/svgs/brands/github.svg" alt="Code" width="15" height="15">](github.com/jwkirchenbauer/lm-watermarking) ![LLM](https://img.shields.io/badge/LLM-589cf4) ![ICML'23](https://img.shields.io/badge/ICML'23-f1b800) ![Best Paper](https://img.shields.io/badge/Best_paper-ff0000)
